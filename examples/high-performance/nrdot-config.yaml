# High-Performance NRDOT-HOST Configuration
# Optimized for maximum throughput and minimal latency

# Server configuration
server:
  host: "0.0.0.0"
  port: 8080
  log_level: "warn"  # Reduce logging overhead
  max_procs: 0       # Use all available CPUs
  
  # Performance tuning
  read_timeout: "30s"
  write_timeout: "30s"
  idle_timeout: "120s"
  max_header_bytes: 1048576  # 1MB
  
  # HTTP/2 support
  http2:
    enabled: true
    max_concurrent_streams: 1000
    
  # Connection pooling
  keep_alive:
    enabled: true
    max_idle_conns: 1000
    max_idle_conns_per_host: 100
    idle_conn_timeout: "90s"

# API configuration
api:
  enabled: true
  compression:
    enabled: true
    level: 6  # Balance between speed and compression
  
  # Disable features that impact performance
  cors:
    enabled: false
  rate_limit:
    enabled: false
  
  # Request handling
  max_request_size: "10MB"
  request_timeout: "30s"
  
  # Circuit breaker for downstream protection
  circuit_breaker:
    enabled: true
    threshold: 0.5
    timeout: "10s"
    max_requests: 100

# High-performance data sources
sources:
  - name: "kafka-high-throughput"
    type: "kafka"
    config:
      brokers: ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
      topics: ["events-0", "events-1", "events-2", "events-3"]
      consumer_group: "nrdot-hp"
      
      # Kafka performance settings
      fetch_min_bytes: 1048576      # 1MB
      fetch_max_wait: "100ms"
      max_poll_records: 5000
      session_timeout: "30s"
      heartbeat_interval: "3s"
      
      # Parallel consumption
      partition_assignment: "range"
      enable_auto_commit: false
      isolation_level: "read_uncommitted"
      
      # Buffer tuning
      receive_buffer: 65536
      send_buffer: 131072
      
  - name: "grpc-stream"
    type: "grpc"
    config:
      port: 9090
      max_message_size: "100MB"
      max_concurrent_streams: 1000
      
      # gRPC performance
      keepalive:
        time: "30s"
        timeout: "10s"
        permit_without_stream: true
      
      # Connection settings
      initial_window_size: 1048576
      initial_conn_window_size: 16777216
      
  - name: "tcp-raw"
    type: "tcp"
    config:
      port: 9091
      protocol: "binary"
      max_connections: 10000
      buffer_size: 65536
      
      # TCP tuning
      tcp_nodelay: true
      tcp_keepalive: true
      socket_buffer: 1048576

# Optimized processing pipeline
processors:
  - name: "batch-aggregator"
    type: "batch"
    config:
      size: 10000
      timeout: "100ms"
      parallel_batches: 4
      
  - name: "parallel-processor"
    type: "parallel"
    config:
      workers: 16
      queue_size: 100000
      strategy: "round_robin"
      
  - name: "filter-fast"
    type: "filter"
    config:
      expression: "status == 'active'"
      compiled: true  # Pre-compile expressions
      cache_size: 10000
      
  - name: "transform-efficient"
    type: "transform"
    config:
      engine: "native"  # Use native Go instead of scripting
      parallel: true
      workers: 8
      mappings:
        - source: "$.id"
          target: "event_id"
          type: "string"
        - source: "$.ts"
          target: "timestamp"
          type: "int64"
          
  - name: "compress"
    type: "compress"
    config:
      algorithm: "snappy"  # Fast compression
      level: 1
      parallel: true

# High-throughput outputs
outputs:
  - name: "clickhouse"
    type: "clickhouse"
    config:
      hosts: ["clickhouse1:9000", "clickhouse2:9000"]
      database: "nrdot"
      table: "events"
      
      # Batch settings
      batch_size: 100000
      batch_timeout: "1s"
      max_batches_in_flight: 10
      
      # Connection pool
      max_open_conns: 50
      max_idle_conns: 25
      conn_max_lifetime: "5m"
      
      # Performance options
      async_insert: true
      compression: "lz4"
      
  - name: "s3-parquet"
    type: "s3"
    config:
      bucket: "nrdot-data"
      region: "us-east-1"
      
      # Parquet optimizations
      format: "parquet"
      compression: "snappy"
      row_group_size: 134217728  # 128MB
      page_size: 1048576         # 1MB
      
      # Batching
      batch_size: 50000
      batch_timeout: "30s"
      parallel_uploads: 10
      
      # S3 performance
      multipart_threshold: "100MB"
      multipart_concurrency: 10
      storage_class: "STANDARD"
      
  - name: "redis-cache"
    type: "redis"
    config:
      addrs: ["redis1:6379", "redis2:6379", "redis3:6379"]
      db: 0
      
      # Connection pool
      pool_size: 100
      min_idle_conns: 50
      max_retries: 3
      
      # Performance
      pipeline_length: 100
      pipeline_timeout: "100ms"
      read_timeout: "3s"
      write_timeout: "3s"
      
      # Data settings
      ttl: "3600s"
      max_entry_size: "1MB"

# Memory management
memory:
  # Garbage collection
  gc_percent: 100  # Less frequent GC
  gc_target_percentage: 80
  
  # Memory limits
  soft_limit: "16GB"
  hard_limit: "20GB"
  
  # Buffer pools
  buffer_pools:
    enabled: true
    sizes: [512, 1024, 4096, 8192, 16384, 32768, 65536]
    
  # Object pools
  object_pools:
    events: 100000
    batches: 1000
    connections: 1000

# CPU optimization
cpu:
  # CPU affinity
  affinity:
    enabled: true
    cpus: [0, 1, 2, 3, 4, 5, 6, 7]  # Pin to specific CPUs
    
  # NUMA awareness
  numa:
    enabled: true
    node: 0
    
  # Thread tuning
  runtime_threads: 16
  io_threads: 8
  worker_threads: 32

# Network optimization
network:
  # TCP tuning
  tcp:
    no_delay: true
    keep_alive: true
    keep_alive_period: "30s"
    
  # Buffer sizes
  receive_buffer: 4194304  # 4MB
  send_buffer: 4194304     # 4MB
  
  # Connection limits
  max_connections: 100000
  connection_timeout: "5s"
  
  # HTTP client
  http_client:
    max_idle_conns: 1000
    max_conns_per_host: 100
    idle_conn_timeout: "90s"
    tls_handshake_timeout: "10s"
    expect_continue_timeout: "1s"
    
# Caching
cache:
  # Multi-level cache
  l1:
    type: "memory"
    size: "4GB"
    ttl: "300s"
    eviction: "lru"
    
  l2:
    type: "redis"
    size: "100GB"
    ttl: "3600s"
    
  # Cache warming
  warming:
    enabled: true
    interval: "5m"
    parallel: 4

# Monitoring (minimal overhead)
monitoring:
  # Metrics collection
  metrics:
    enabled: true
    interval: "30s"
    percentiles: [0.5, 0.95, 0.99]
    
  # Sampling
  sampling:
    enabled: true
    rate: 0.01  # 1% sampling
    
  # Export
  export:
    type: "prometheus"
    buffer_size: 100000
    flush_interval: "10s"

# Performance profiles
profiles:
  - name: "ultra-high-throughput"
    conditions:
      time: "peak_hours"
      load: "high"
    settings:
      batch_size: 50000
      workers: 64
      gc_percent: 200
      
  - name: "balanced"
    conditions:
      time: "normal_hours"
      load: "medium"
    settings:
      batch_size: 10000
      workers: 32
      gc_percent: 100
      
  - name: "low-latency"
    conditions:
      time: "any"
      load: "low"
    settings:
      batch_size: 1000
      workers: 16
      gc_percent: 50

# Optimizations
optimizations:
  # Compiler optimizations
  compiler:
    inline_budget: 1000
    escape_analysis: true
    bounds_check_elimination: true
    
  # Runtime optimizations
  runtime:
    stack_size: "8MB"
    preemption: false
    async_preemption: false
    
  # Algorithm selection
  algorithms:
    hash: "xxhash"      # Fastest hash
    compression: "s2"    # Fastest compression
    serialization: "msgpack"  # Efficient serialization